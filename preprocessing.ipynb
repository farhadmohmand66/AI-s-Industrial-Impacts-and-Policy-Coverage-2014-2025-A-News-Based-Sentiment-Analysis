{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U4d2ysXrGdp6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bRCHaV5HGihB"
   },
   "outputs": [],
   "source": [
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "df = pd.read_json(\"hf://datasets/yjernite/news-ai-labor-coverage/news_jobs_dataset_2022-12-01_2025-07-01.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HXNOTBHgIf3r",
    "outputId": "b9b5f9cf-6f41-4fac-a72c-0facd9904a3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22270 entries, 0 to 22269\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   title_s          22270 non-null  object        \n",
      " 1   title_dl         22270 non-null  object        \n",
      " 2   source_url       22270 non-null  object        \n",
      " 3   authors          22270 non-null  object        \n",
      " 4   snippet_s        22270 non-null  object        \n",
      " 5   text             22270 non-null  object        \n",
      " 6   date             22270 non-null  datetime64[ns]\n",
      " 7   publish_date_dl  22270 non-null  object        \n",
      " 8   url              22270 non-null  object        \n",
      " 9   matches          22270 non-null  object        \n",
      "dtypes: datetime64[ns](1), object(9)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "shIf5ZTzGnRi",
    "outputId": "35bc36e2-7e81-4b2c-f9d6-ba68a78dc447"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "LqVkW-VpPh4j"
   },
   "outputs": [],
   "source": [
    "# Reset the index to include it as a column and make it permanent\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AB2dV9oakXpH",
    "outputId": "b3046f21-883c-421c-ddb3-b2cb468885fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22270 entries, 0 to 22269\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   index            22270 non-null  int64         \n",
      " 1   title_s          22270 non-null  object        \n",
      " 2   title_dl         22270 non-null  object        \n",
      " 3   source_url       22270 non-null  object        \n",
      " 4   authors          22270 non-null  object        \n",
      " 5   snippet_s        22270 non-null  object        \n",
      " 6   text             22270 non-null  object        \n",
      " 7   date             22270 non-null  datetime64[ns]\n",
      " 8   publish_date_dl  22270 non-null  object        \n",
      " 9   url              22270 non-null  object        \n",
      " 10  matches          22270 non-null  object        \n",
      "dtypes: datetime64[ns](1), int64(1), object(9)\n",
      "memory usage: 1.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Take the first 10,000 rows from df and assign to sample_df\n",
    "sample_df = df.copy()\n",
    "\n",
    "# Display info to verify the new sample_df\n",
    "print(sample_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0UYSbskGvkx4",
    "outputId": "57918653-2fec-406f-8279-e9db83725442"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'title_s', 'title_dl', 'source_url', 'authors', 'snippet_s',\n",
      "       'text', 'date', 'publish_date_dl', 'url', 'matches'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(sample_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OoRlIAy3pjA8",
    "outputId": "73965e1d-b815-4f1a-8af9-05ed471e9a05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ftfy\n",
      "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy) (0.2.13)\n",
      "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: ftfy\n",
      "Successfully installed ftfy-6.3.1\n"
     ]
    }
   ],
   "source": [
    "%pip install ftfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "isQf5Q34XQAj",
    "outputId": "59c64533-7cb2-4b3f-b9a0-c18bed56b170"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CLEANED ARTICLE ===\n",
      "friday causing widespread damage across several counties. key developments epicenter near ridgecrest felt from la to las vegas aftershocks recorded why does this keep happening? experts weigh in photos see the damage said maria gonzalez of los angeles. my entire kitchen collapsed dishes everywhere what are we supposed to do now? check for gas leaks immediately. expect prolonged power outages. avoid damaged structures. when will help arrive? soon says governor .\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import ftfy\n",
    "\n",
    "def clean_news_article(article_text):\n",
    "    \"\"\"\n",
    "    Clean news articles into a single paragraph for sentiment analysis:\n",
    "    - Removes all metadata, special characters, and excessive punctuation\n",
    "    - Keeps only clean sentences with basic punctuation (. and ?)\n",
    "    - Returns clean single paragraph text\n",
    "    \"\"\"\n",
    "    if not isinstance(article_text, str) or not article_text.strip():\n",
    "        return \"\"\n",
    "\n",
    "    # Initial text normalization\n",
    "    text = ftfy.fix_text(article_text)\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text(separator=\" \")\n",
    "\n",
    "    # Remove metadata patterns more aggressively\n",
    "    metadata_patterns = [\n",
    "        r'^\\s*(by|written by|reported by|staff|correspondent|contributor)[^.!?]*[.!?]',\n",
    "        r'(updated|published|posted|last updated|last modified)[^.!?]*[.!?]',\n",
    "        r'\\([^)]*ap[^)]*\\)',  # Remove AP-style credits\n",
    "        r'\\[.*?\\]|\\(.*?\\)|\\<.*?\\>|\\{.*?\\}',  # All brackets\n",
    "        r'\\b(photo|image|video|audio|footage|gallery|infographic):[^.!?]*',\n",
    "        r'\\b(share|comment|like|follow|subscribe|click|watch|read|view)[^.!?]*',\n",
    "        r'@\\w+|#\\w+',  # Social media\n",
    "        r'\\b(facebook|twitter|instagram|linkedin|youtube)\\b[^.!?]*',\n",
    "        r'\\b(read more|continue reading|related|more|also|advertisement|sponsored)[^.!?]*',\n",
    "        r'\\b(breaking|developing story|exclusive|analysis|opinion)[^.!?]*',\n",
    "        r'^[a-z\\s]*[—\\-]\\s*',  # Location tags\n",
    "        r'[\\|\\:\\+\\\"]',  # Remove all pipes, colons, plus signs and quotes\n",
    "    ]\n",
    "\n",
    "    for pattern in metadata_patterns:\n",
    "        text = re.sub(pattern, ' ', text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Remove dates and times (including time period markers)\n",
    "    text = re.sub(r'\\b\\d{1,2}[/\\-\\.]\\d{1,2}[/\\-\\.]\\d{2,4}\\b', ' ', text)\n",
    "    text = re.sub(r'\\b(jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec)[a-z]*\\.?\\s*\\d{1,2},?\\s*\\d{4}\\b', ' ', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'\\b\\d{1,2}\\s*[ap]\\.?m\\.?\\b', ' ', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'\\.\\s*[ap]\\.?m\\.?\\b', ' ', text, flags=re.IGNORECASE)  # Handle cases where time was partially removed\n",
    "\n",
    "    # Remove all numbers\n",
    "    text = re.sub(r'\\b\\d+\\b', ' ', text)\n",
    "\n",
    "    # Clean bullet points and other special characters\n",
    "    text = re.sub(r'[\\-\\*]\\s*', ' ', text)  # Remove bullet points\n",
    "\n",
    "    # Clean and normalize text\n",
    "    text = re.sub(r'([.!?])\\s+', r'\\1 ', text)  # Normalize sentence spacing\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove excessive punctuation\n",
    "    text = re.sub(r'[!,\"]', ' ', text)  # Remove quotes, exclamation marks\n",
    "    text = re.sub(r'([,.!?])\\1+', r'\\1', text)  # Remove duplicate punctuation\n",
    "    text = re.sub(r'\\s([,.!?])(\\s|$)', r'\\1 ', text)  # Fix spacing before punctuation\n",
    "    text = re.sub(r'([a-z])\\s*-\\s*([a-z])', r'\\1 \\2', text)  # Fix hyphen spacing\n",
    "\n",
    "    # Extract complete sentences\n",
    "    sentences = []\n",
    "    for sentence in re.split(r'(?<=[.!?])\\s+', text):\n",
    "        sentence = sentence.strip()\n",
    "        # Only keep sentences with at least 3 words and proper punctuation\n",
    "        if (len(sentence.split()) >= 3 and\n",
    "            re.search(r'[.!?]$', sentence) and\n",
    "            re.search(r'[a-z]', sentence)):\n",
    "            # Clean sentence further\n",
    "            sentence = re.sub(r'^[^a-z]*', '', sentence)\n",
    "            sentence = sentence.capitalize()\n",
    "            sentences.append(sentence)\n",
    "\n",
    "    # Combine into paragraph with proper spacing\n",
    "    paragraph = ' '.join(sentences)\n",
    "\n",
    "    # Final cleaning\n",
    "    paragraph = re.sub(r'\\s([.,!?])(\\s|$)', r'\\1 ', paragraph)\n",
    "    paragraph = re.sub(r'\\s+', ' ', paragraph).strip()\n",
    "    paragraph = paragraph.lower()\n",
    "\n",
    "    return paragraph\n",
    "\n",
    "# Example usage with long messy article\n",
    "messy_article = \"\"\"\n",
    "BREAKING: Major Earthquake Strikes California [VIDEO]\n",
    "\n",
    "By John Smith | Updated: July 15, 2023 5:30 PM PST\n",
    "\n",
    "LOS ANGELES (AP) — A powerful magnitude 7.1 earthquake rocked Southern California\n",
    "at 3:15 p.m. Friday, causing widespread damage across several counties.\n",
    "\n",
    "Key developments:\n",
    "- Epicenter near Ridgecrest (same area as 2019 quakes)\n",
    "- Felt from LA to Las Vegas\n",
    "- 20+ aftershocks recorded\n",
    "- Why does this keep happening? Experts weigh in [INTERVIEW]\n",
    "\n",
    "PHOTOS: See the damage (Warning: Graphic content)\n",
    "VIDEO: Security cameras capture moment quake hit\n",
    "\n",
    "\"This was terrifying!\" said Maria Gonzalez, 42, of Los Angeles.\n",
    "\"My entire kitchen collapsed - dishes everywhere! What are we supposed to do now?\"\n",
    "\n",
    "Officials warn:\n",
    "1. Check for gas leaks immediately\n",
    "2. Expect prolonged power outages\n",
    "3. Avoid damaged structures\n",
    "4. When will help arrive? \"Soon\" says governor\n",
    "\n",
    "RELATED:\n",
    "Earthquake preparedness guide (2019 update)\n",
    "California's seismic history (archival footage)\n",
    "\n",
    "Share your experience: #CAquake\n",
    "Follow live updates: @CalEMA\n",
    "\n",
    "Advertisement: Home insurance deals after quakes!\n",
    "\n",
    "More on this developing story...\n",
    "\"\"\"\n",
    "clean_result = clean_news_article(messy_article)\n",
    "print(\"=== CLEANED ARTICLE ===\")\n",
    "print(clean_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7045-HpmKIdx",
    "outputId": "bd2a5c74-010c-4fcf-b720-218927834cba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "from tqdm.auto import tqdm as tqdm_auto\n",
    "tqdm_auto.pandas() # Use the imported tqdm_auto for pandas integration\n",
    "\n",
    "sample_df['cleaned_text'] = sample_df['text'].progress_apply(clean_news_article)\n",
    "\n",
    "print(\"\\nStep 1 Verification: Preprocessing\")\n",
    "print(\"cleaned text:\", sample_df['cleaned_text'].iloc[0][:200])\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aZhXDDATC21P"
   },
   "outputs": [],
   "source": [
    "def clean_snipet(s):\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    s = re.sub(r\"<[^>]+>\", \" \", str(s))  # remove HTML tags\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    s = s.lower()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hDTAFPOjDDux",
    "outputId": "b57c3f92-9e87-4a3b-fa9c-7b7523b00937"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'title_s', 'title_dl', 'source_url', 'authors', 'snippet_s',\n",
       "       'text', 'date', 'publish_date_dl', 'url', 'matches', 'cleaned_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174,
     "referenced_widgets": [
      "bdb60dc87e3d439c92b36cdd643bf8a8",
      "3f2aeef256c3446f9dd7474c8ef807c5",
      "9989c6c90d3346b29e450e851fbabbd3",
      "198ce72696d84010b5caa9619efb3d71",
      "eec03be09a424b2c84bb8b389810edb8",
      "3fe18969c60b4507807f3bd06e401e63",
      "6a7bef04646d4306a014ea034b5c385e",
      "b8d5ba1ff03b4e828804c5ccbe0f2178",
      "cb110207d43241bc9a377a2d69586316",
      "03f617ca91bc4539a65359e91d50a289",
      "d25db5320a484f7a915ce968d1011396",
      "297e612c81c94410b79f9cb3e50ad8a9",
      "38cf6f11c3da4360b7c427124fa12552",
      "f120d004a77a4ca8a4d6f89a3e40afd8",
      "ffe3d991bd904b4ea870e31abd941702",
      "2f7052816a2546b8a719de5d85264823",
      "1d1e274ad4404710a3624bb670e3e574",
      "210de2088f2e4b628417f973d1f2fc7c",
      "8256a44e759b48a38ba292918e72e573",
      "36d25d4b8ed94b9d86f93f2458873cc0",
      "95ec89dd09b64e68b197fc2bef1f6147",
      "980fe5b33fd247f587a8b9cc5c153b94"
     ]
    },
    "id": "YhB-v8FzC-QT",
    "outputId": "03d445e1-09a9-4eff-f0fe-573c41594cb5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdb60dc87e3d439c92b36cdd643bf8a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22270 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "297e612c81c94410b79f9cb3e50ad8a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22270 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 1 Verification: Preprocessing\n",
      "cleaned text: in this article we explore how ai is likely to affect employment and the distribution of income. we argue that ai will indeed reduce drastically the need of ...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "sample_df['snippet_s'] = sample_df['snippet_s'].progress_apply(clean_snipet)\n",
    "sample_df['title_dl'] = sample_df['title_dl'].progress_apply(clean_snipet)\n",
    "print(\"\\nStep 1 Verification: Preprocessing\")\n",
    "print(\"cleaned text:\", sample_df['snippet_s'].iloc[0][:200])\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "fW-NEcF0GFpt",
    "outputId": "a175e408-7db9-45a0-c893-65240f4c93e7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1984-06-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-08-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-08-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> object</label>"
      ],
      "text/plain": [
       "0    1984-06-15\n",
       "1    2014-08-06\n",
       "2    2014-08-06\n",
       "Name: date, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert the 'date' column to a standard date format (YYYY-MM-DD)\n",
    "sample_df['date'] = sample_df['date'].dt.date\n",
    "display(sample_df['date'].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ff61FvEurBU1"
   },
   "outputs": [],
   "source": [
    "# sample_df1.head().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "prnauqEHk5KD"
   },
   "outputs": [],
   "source": [
    "# print(sample_df.iloc[2].to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uzYczF95SlOI"
   },
   "outputs": [],
   "source": [
    "sample_df = sample_df[['index', 'date', 'title_dl', 'cleaned_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vVPrRuUU7d38",
    "outputId": "85a78c46-226f-455e-b932-4ca171402451"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample shape: (22270, 4)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22270 entries, 0 to 22269\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   index         22270 non-null  int64 \n",
      " 1   date          22270 non-null  object\n",
      " 2   title_dl      22270 non-null  object\n",
      " 3   cleaned_text  22270 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 696.1+ KB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sample shape: {sample_df.shape}\")\n",
    "sample_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WREVae-eGbWm"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import tiktoken\n",
    "import re\n",
    "\n",
    "# Initialize tokenizer - use 'gpt-4' as proxy (similar tokenization)\n",
    "try:\n",
    "    tokenizer = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "except KeyError:\n",
    "    # Fallback to cl100k_base which works for most modern models\n",
    "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "def count_tokens(text):\n",
    "    \"\"\"Count tokens using tiktoken\"\"\"\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "def smart_truncate_article(article_text, max_tokens):\n",
    "    \"\"\"\n",
    "    Truncates ONLY if article exceeds max_tokens, keeping most important sentences\n",
    "    in ORIGINAL order. Returns unchanged text if already short enough.\n",
    "    \"\"\"\n",
    "    # Clean text first (optional)\n",
    "    article_text = re.sub(r'\\s+', ' ', article_text).strip()\n",
    "\n",
    "    # Skip processing if within limit\n",
    "    if count_tokens(article_text) <= max_tokens:\n",
    "        return article_text\n",
    "\n",
    "    # Step 1: Split into sentences\n",
    "    sentences = sent_tokenize(article_text)\n",
    "    if len(sentences) <= 1:\n",
    "        # Fallback for very long single-sentence texts\n",
    "        return tokenizer.decode(tokenizer.encode(article_text)[:max_tokens])\n",
    "\n",
    "    # Step 2: Calculate sentence importance (TF-IDF)\n",
    "    try:\n",
    "        vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "        tfidf = vectorizer.fit_transform(sentences)\n",
    "        sentence_scores = tfidf.sum(axis=1).A1\n",
    "    except ValueError:\n",
    "        # Fallback if TF-IDF fails (e.g., all stop words)\n",
    "        return \" \".join(sentences[:int(len(sentences)*0.5)])  # Take first half\n",
    "\n",
    "    # Step 3: Pair scores with original indices\n",
    "    scored_sentences = [(score, idx) for idx, score in enumerate(sentence_scores)]\n",
    "\n",
    "    # Step 4: Sort by score (highest first)\n",
    "    scored_sentences.sort(reverse=True, key=lambda x: x[0])\n",
    "\n",
    "    # Step 5: Select top sentences IN ORIGINAL ORDER until token limit\n",
    "    selected_indices = sorted([idx for _, idx in scored_sentences])  # Maintain original order\n",
    "    truncated_text = []\n",
    "    current_tokens = 0\n",
    "\n",
    "    for idx in selected_indices:\n",
    "        sentence = sentences[idx]\n",
    "        sentence_tokens = count_tokens(sentence)\n",
    "        if current_tokens + sentence_tokens > max_tokens:\n",
    "            break\n",
    "        truncated_text.append(sentence)\n",
    "        current_tokens += sentence_tokens\n",
    "\n",
    "    # Fallback if no sentences were selected\n",
    "    if not truncated_text:\n",
    "        return tokenizer.decode(tokenizer.encode(article_text)[:max_tokens])\n",
    "\n",
    "    return \" \".join(truncated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SXwUtFOOWBfr",
    "outputId": "072d37b4-4515-49e0-ec54-71a2e93a5361"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count for the text in sample_df['cleaned_text'].iloc[2]: 2500\n"
     ]
    }
   ],
   "source": [
    "# Get the cleaned text from the third row\n",
    "text_to_count = sample_df['cleaned_text'].iloc[2]\n",
    "\n",
    "# Count the tokens using the defined function\n",
    "token_count = count_tokens(text_to_count)\n",
    "\n",
    "# Display the result\n",
    "print(f\"Token count for the text in sample_df['cleaned_text'].iloc[2]: {token_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "msav6EyIqbrV",
    "outputId": "7e7bfa03-7e08-450b-809c-25af3cecaa06"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O5GHWCWekyEe",
    "outputId": "a47ce7fd-37bd-40f9-b035-72e1c622eefc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncating articles: 100%|██████████| 22270/22270 [01:09<00:00, 318.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Truncated text lengths: count    22270.000000\n",
      "mean      4199.058105\n",
      "std       2909.390360\n",
      "min          0.000000\n",
      "25%       1383.250000\n",
      "50%       4014.000000\n",
      "75%       7105.750000\n",
      "max      10066.000000\n",
      "Name: cleaned_text, dtype: float64\n",
      "\n",
      "Sample truncated text:\n",
      "Token count for the text in sample_df['cleaned_text'].iloc[2]: 2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you have a DataFrame 'sample_df' with 'cleaned_text' column\n",
    "# Apply truncation with progress bar\n",
    "for idx, text in tqdm(sample_df['cleaned_text'].items(), total=len(sample_df), desc=\"Truncating articles\"):\n",
    "    # Skip processing if text is empty/NaN\n",
    "    if pd.isna(text) or not str(text).strip():\n",
    "        sample_df.at[idx, 'cleaned_text'] = \"\"\n",
    "        continue\n",
    "\n",
    "    # Apply truncation (2000 token limit)\n",
    "    truncated = smart_truncate_article(str(text), max_tokens=1400)\n",
    "    sample_df.at[idx, 'cleaned_text'] = truncated  # Update the original column with truncated text\n",
    "\n",
    "# Verify results\n",
    "print(f\"\\nTruncated text lengths: {sample_df['cleaned_text'].str.len().describe()}\")\n",
    "print(\"\\nSample truncated text:\")\n",
    "print(f\"Token count for the text in sample_df['cleaned_text'].iloc[2]: {token_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "74I4tcfsX945"
   },
   "outputs": [],
   "source": [
    "# Define the path to save the JSON file in Google Drive\n",
    "output_path = '/content/drive/MyDrive/sentiment_analysis/sample_df.json'\n",
    "\n",
    "# Save the DataFrame to JSON format\n",
    "sample_df.to_json(output_path, orient='records', indent=2)\n",
    "\n",
    "print(f\"DataFrame successfully saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0TwuX38QvoHg"
   },
   "outputs": [],
   "source": [
    "############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E-YDDysAN7_2",
    "outputId": "8f6d952c-7ff1-4ad2-a4d2-c8932674d661"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSeek API client initialized.\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# DeepSeek API key & endpoint\n",
    "# ============================================\n",
    "DEEPSEEK_API_KEY = \"Your api key\"\n",
    "# DEEPSEEK_URL = \"https://api.deepseek.com/chat/completions\"\n",
    "print(\"DeepSeek API client initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FIVsXLiip6v6"
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# STEP 1 — Imports & Setup\n",
    "# =========================\n",
    "import time\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=DEEPSEEK_API_KEY, base_url=\"https://api.deepseek.com\")\n",
    "# File to store partial results\n",
    "OUTPUT_FILE = \"/content/drive/MyDrive/sentiment_analysis/deepseek_ai_job_analysis.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "utxXqnr4qDCh",
    "outputId": "bfcf502d-2cf7-43f2-ce31-264f6119579e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total articles: 11270\n",
      "Already processed: 217\n",
      "Remaining: 11173\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# STEP 2 — Load Dataset\n",
    "# =========================\n",
    "all_articles = sample_df.to_dict(orient=\"records\")\n",
    "\n",
    "# =========================\n",
    "# STEP 3 — Resume Progress\n",
    "# =========================\n",
    "if os.path.exists(OUTPUT_FILE):\n",
    "    with open(OUTPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        saved_data = json.load(f)\n",
    "    processed_ids = {int(item[\"article_id\"]) for item in saved_data}\n",
    "else:\n",
    "    saved_data = []\n",
    "    processed_ids = set()\n",
    "\n",
    "remaining_articles = [a for a in all_articles if a[\"index\"] not in processed_ids]\n",
    "\n",
    "print(f\"Total articles: {len(all_articles)}\")\n",
    "print(f\"Already processed: {len(processed_ids)}\")\n",
    "print(f\"Remaining: {len(remaining_articles)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4qEsPB8Uq7xr"
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# STEP 4 — Save Function\n",
    "# =========================\n",
    "def save_partial_results(results_list):\n",
    "    \"\"\"Append new batch results to JSON file.\"\"\"\n",
    "    global saved_data\n",
    "    saved_data.extend(results_list)\n",
    "    with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(saved_data, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "elzdjnNmUWbX"
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# STEP 5 — API Call Function\n",
    "# =========================\n",
    "def analyze_batch(batch_articles):\n",
    "    \"\"\"Send batch of articles to DeepSeek API.\"\"\"\n",
    "    prompt = \"\"\"\n",
    "You are an AI analyst extracting workforce and policy insights from articles. Follow these rules:\n",
    "\n",
    "### Output Format (STRICT JSON):\n",
    "{\n",
    "  \"ARTICLE_<id>\": {\n",
    "    \"job_roles\": [{\n",
    "      \"role\": \"(explicit job title or inferred role) | null if no evidence\",\n",
    "      \"industry\": \"(e.g., 'tech', 'healthcare', 'education') | null if unspecified\",\n",
    "      \"ai_impact\": \"augmented|at_risk|transformed_role|emerging_role|obsolete_role | null if unclear\",\n",
    "      \"evidence\": \"(EXACT quote from text) | null if role is inferred without direct support\",\n",
    "      \"sentiment_score\": \"(-1 to 1) | null if no sentiment detectable\",\n",
    "      \"confidence\": \"(0 to 1) | null if evidence is too weak\"\n",
    "    }],\n",
    "    \"policy_recommendations\": [{\n",
    "      \"category\": \"training_upskilling|ai_governance_ethics|innovation_incentives|worker_protection|economic_transition_support | null if unclear\",\n",
    "      \"recommendations\": [\"(specific action from text)\"] | [] if none\n",
    "    }]\n",
    "  }\n",
    "}\n",
    "\n",
    "### Rules:\n",
    "1. **Job Roles**:\n",
    "   - Roles MUST be explicitly named or strongly implied (e.g., \"AI ethicists will be in demand\" → role: \"AI ethicist\").\n",
    "   - If no role/industry is mentioned, set to `null`.\n",
    "   - `ai_impact` and `evidence` are REQUIRED. If missing, set to `null`.\n",
    "   - `sentiment_score`/`confidence`: Only provide if calculable (e.g., \"AI threatens jobs\" → -0.6). Else, `null`.\n",
    "\n",
    "2. **Policy Recommendations**:\n",
    "   - Only include policies EXPLICITLY stated (e.g., \"Policymakers should fund AI training\").\n",
    "   - If no recommendations exist, return `\"policy_recommendations\": []`.\n",
    "   - Never infer policies without direct evidence.\n",
    "\n",
    "3. **Strict Validation**:\n",
    "   - If a field lacks evidence, set it to `null` or `[]` (for arrays).\n",
    "   - Never hallucinate. Omit entire `job_roles` array if no roles exist.\n",
    "\n",
    "### Example Outputs:\n",
    "1. **Valid Role**:\n",
    "   {\n",
    "     \"role\": \"AI ethicist\",\n",
    "     \"industry\": \"tech\",\n",
    "     \"ai_impact\": \"emerging_role\",\n",
    "     \"evidence\": \"Demand for AI ethics professionals will grow by 2025.\",\n",
    "     \"sentiment_score\": 0.7,\n",
    "     \"confidence\": 0.8\n",
    "   }\n",
    "\n",
    "2. **Incomplete Data**:\n",
    "   {\n",
    "     \"role\": \"Data analyst\",\n",
    "     \"industry\": null,  // Not mentioned\n",
    "     \"ai_impact\": \"augmented\",\n",
    "     \"evidence\": \"AI will enhance data analysis tasks.\",\n",
    "     \"sentiment_score\": 0.5,\n",
    "     \"confidence\": null  // Subjective impact\n",
    "   }\n",
    "\n",
    "3. **No Policies**:\n",
    "   \"policy_recommendations\": []\n",
    "\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an AI labor market analyst.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"user\", \"content\": str(batch_articles)}\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=messages,\n",
    "        temperature=0.3\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# =========================\n",
    "# STEP 6 — Safe JSON Parsing\n",
    "# =========================\n",
    "def safe_json_parse(text):\n",
    "    \"\"\"Try to parse model output as JSON, fixing common errors.\"\"\"\n",
    "    try:\n",
    "        # Remove any leading/trailing text outside JSON\n",
    "        json_str = re.search(r\"\\{.*\\}\", text, re.DOTALL)\n",
    "        if json_str:\n",
    "            text = json_str.group(0)\n",
    "\n",
    "        # Fix trailing commas\n",
    "        text = re.sub(r\",\\s*}\", \"}\", text)\n",
    "        text = re.sub(r\",\\s*]\", \"]\", text)\n",
    "\n",
    "        return json.loads(text)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ JSON parse error: {e}\")\n",
    "        return None\n",
    "\n",
    "# =========================\n",
    "# STEP 7 — Process API Result\n",
    "# =========================\n",
    "def process_batch_result(batch_result, batch_articles):\n",
    "    \"\"\"Convert API result into structured list of dicts.\"\"\"\n",
    "    results_list = []\n",
    "    parsed = safe_json_parse(batch_result)\n",
    "\n",
    "    if parsed:\n",
    "        if isinstance(parsed, dict):\n",
    "            for article_key, analysis_data in parsed.items():\n",
    "                article_id = int(article_key.split('_')[-1]) if '_' in article_key else None\n",
    "                if article_id:\n",
    "                    results_list.append({\n",
    "                        \"article_id\": article_id,\n",
    "                        \"job_roles\": analysis_data.get(\"job_roles\", []),\n",
    "                        \"policy_recommendations\": analysis_data.get(\"policy_recommendations\", [])\n",
    "                    })\n",
    "    else:\n",
    "        # If parsing fails, save None for all articles in batch\n",
    "        for art in batch_articles:\n",
    "            results_list.append({\n",
    "                \"article_id\": art[\"index\"],\n",
    "                \"job_roles\": None,\n",
    "                \"policy_recommendations\": None\n",
    "            })\n",
    "\n",
    "    return results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5k1fyr-eRkN5"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "id": "jeJcOq0Yqfvx",
    "outputId": "5ec41af5-256a-4e7f-87eb-d9e13af5e640"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2547588147.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# =========================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining_articles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Processing Articles\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mbatch_articles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremaining_articles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# STEP 8 — Batch Processing Loop\n",
    "# =========================\n",
    "BATCH_SIZE = 5\n",
    "for i in tqdm(range(0, len(remaining_articles), BATCH_SIZE), desc=\"Processing Articles\"):\n",
    "    batch_articles = remaining_articles[i:i+BATCH_SIZE]\n",
    "    try:\n",
    "        api_result = analyze_batch(batch_articles)\n",
    "        processed_results = process_batch_result(api_result, batch_articles)\n",
    "        save_partial_results(processed_results)\n",
    "        time.sleep(1)  # avoid rate limit\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in batch {i//BATCH_SIZE + 1}: {e}\")\n",
    "        save_partial_results([{\n",
    "            \"article_id\": art[\"index\"],\n",
    "            \"job_roles\": None,\n",
    "            \"policy_recommendations\": None\n",
    "        } for art in batch_articles])\n",
    "        time.sleep(3)  # backoff\n",
    "\n",
    "print(\"✅ Processing complete. Results saved to\", OUTPUT_FILE)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "03f617ca91bc4539a65359e91d50a289": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "198ce72696d84010b5caa9619efb3d71": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_03f617ca91bc4539a65359e91d50a289",
      "placeholder": "​",
      "style": "IPY_MODEL_d25db5320a484f7a915ce968d1011396",
      "value": " 22270/22270 [00:00&lt;00:00, 79171.49it/s]"
     }
    },
    "1d1e274ad4404710a3624bb670e3e574": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "210de2088f2e4b628417f973d1f2fc7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "297e612c81c94410b79f9cb3e50ad8a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_38cf6f11c3da4360b7c427124fa12552",
       "IPY_MODEL_f120d004a77a4ca8a4d6f89a3e40afd8",
       "IPY_MODEL_ffe3d991bd904b4ea870e31abd941702"
      ],
      "layout": "IPY_MODEL_2f7052816a2546b8a719de5d85264823"
     }
    },
    "2f7052816a2546b8a719de5d85264823": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "36d25d4b8ed94b9d86f93f2458873cc0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "38cf6f11c3da4360b7c427124fa12552": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1d1e274ad4404710a3624bb670e3e574",
      "placeholder": "​",
      "style": "IPY_MODEL_210de2088f2e4b628417f973d1f2fc7c",
      "value": "100%"
     }
    },
    "3f2aeef256c3446f9dd7474c8ef807c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3fe18969c60b4507807f3bd06e401e63",
      "placeholder": "​",
      "style": "IPY_MODEL_6a7bef04646d4306a014ea034b5c385e",
      "value": "100%"
     }
    },
    "3fe18969c60b4507807f3bd06e401e63": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a7bef04646d4306a014ea034b5c385e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8256a44e759b48a38ba292918e72e573": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "95ec89dd09b64e68b197fc2bef1f6147": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "980fe5b33fd247f587a8b9cc5c153b94": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9989c6c90d3346b29e450e851fbabbd3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b8d5ba1ff03b4e828804c5ccbe0f2178",
      "max": 22270,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cb110207d43241bc9a377a2d69586316",
      "value": 22270
     }
    },
    "b8d5ba1ff03b4e828804c5ccbe0f2178": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bdb60dc87e3d439c92b36cdd643bf8a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3f2aeef256c3446f9dd7474c8ef807c5",
       "IPY_MODEL_9989c6c90d3346b29e450e851fbabbd3",
       "IPY_MODEL_198ce72696d84010b5caa9619efb3d71"
      ],
      "layout": "IPY_MODEL_eec03be09a424b2c84bb8b389810edb8"
     }
    },
    "cb110207d43241bc9a377a2d69586316": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d25db5320a484f7a915ce968d1011396": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eec03be09a424b2c84bb8b389810edb8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f120d004a77a4ca8a4d6f89a3e40afd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8256a44e759b48a38ba292918e72e573",
      "max": 22270,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_36d25d4b8ed94b9d86f93f2458873cc0",
      "value": 22270
     }
    },
    "ffe3d991bd904b4ea870e31abd941702": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_95ec89dd09b64e68b197fc2bef1f6147",
      "placeholder": "​",
      "style": "IPY_MODEL_980fe5b33fd247f587a8b9cc5c153b94",
      "value": " 22270/22270 [00:00&lt;00:00, 148823.76it/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
